{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hippocorpus_NB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1SqiCWVRPowWo8vfE8cD5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feliciahf/data_science_exam/blob/main/hippocorpus_NB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS0Vz4ExdBMZ"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTSjJzvmc9Xh",
        "outputId": "53974be5-7b7d-4a42-cacd-fd801767f5fa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Naive Bayes model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Accuracies\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-b1BAaGdFhT"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDQVM-btdG3n"
      },
      "source": [
        "# import csv file as dataframe (from GitHub repo)\n",
        "url = 'https://raw.githubusercontent.com/feliciahf/data_science_exam/main/hippoCorpusV2.csv'\n",
        "df = pd.read_csv(url, encoding='latin1')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1UZM-9odH6Q"
      },
      "source": [
        "# remove columns with uninformative information (AssignmentId, WorkerId, recAgnPairId, recImgPairId)\n",
        "uninformative_cols = [\"AssignmentId\", \"WorkerId\", \"recAgnPairId\", \"recImgPairId\"]\n",
        "df = df.drop(columns=uninformative_cols)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPxMdz5t5-0O"
      },
      "source": [
        "# drop retold label\n",
        "df = df[df.memType != 'retold']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ-xhwF_dKxI"
      },
      "source": [
        "# make labels column using numerical values\n",
        "df.memType = pd.Categorical(df.memType)\n",
        "df['label'] = df.memType.cat.codes"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ5IMnIddMcj",
        "outputId": "f6b60c7d-7f6a-4d9c-a768-663e1684f772"
      },
      "source": [
        "# story type corresponding to label\n",
        "print(f\"Label 0: {df.loc[df['label'] == 0,'memType'].unique()}\")\n",
        "print(f\"Label 1: {df.loc[df['label'] == 1,'memType'].unique()}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0: ['imagined']\n",
            "Categories (1, object): ['imagined']\n",
            "Label 1: ['recalled']\n",
            "Categories (1, object): ['recalled']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT6l65DlddfO"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjTGF8paetXx"
      },
      "source": [
        "# case collapsing\n",
        "df['story'] = df.story.map(lambda x: x.lower())\n",
        "# remove punctuation\n",
        "df['story'] = df.story.str.replace('[^\\w\\s]', '')\n",
        "# tokenization\n",
        "df['story'] = df['story'].apply(nltk.word_tokenize)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eKr5f07eheW",
        "outputId": "bca96cb6-dec2-4f9a-a13a-c5949fb68d84"
      },
      "source": [
        "df['story']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [concerts, are, my, most, favorite, thing, and...\n",
              "1       [the, day, started, perfectly, with, a, great,...\n",
              "2       [it, seems, just, like, yesterday, but, today,...\n",
              "3       [five, months, ago, my, niece, and, nephew, we...\n",
              "4       [about, a, month, ago, i, went, to, burning, m...\n",
              "                              ...                        \n",
              "6849    [my, dog, was, diagnosed, with, lymphoma, a, y...\n",
              "6850    [over, my, vacation, from, my, job, i, went, t...\n",
              "6851    [this, event, was, a, birthday, party, for, my...\n",
              "6852    [this, event, occurred, about, two, weeks, ago...\n",
              "6853    [over, the, past, year, i, have, been, involve...\n",
              "Name: story, Length: 5535, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DolDvebrdrIy"
      },
      "source": [
        "# transform data into occurrences\n",
        "# This converts the list of words into space-separated strings\n",
        "df['story'] = df['story'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "counts = count_vect.fit_transform(df['story'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-SfavCqduKf"
      },
      "source": [
        "# tf-idf\n",
        "transformer = TfidfTransformer().fit(counts)\n",
        "counts = transformer.transform(counts)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs8TNY3mduf0"
      },
      "source": [
        "# Training NB model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEv68KmFgIXH"
      },
      "source": [
        "# split data into train (80%) and test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.2, random_state=69)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwCqa8Fvdwyv"
      },
      "source": [
        "# Fit model\n",
        "model = MultinomialNB().fit(X_train, y_train)\n",
        "# Test model\n",
        "predicted = model.predict(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSARKmwTfIb5"
      },
      "source": [
        "# Evaluating NB model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2gxHX8sfKiG",
        "outputId": "1963e74b-7a19-42e0-e1a4-fcb5645231bd"
      },
      "source": [
        "# compute overall accuracy, precision, recall, f1 scores\n",
        "print('Accuracy: ', accuracy_score(y_test, predicted))\n",
        "print('Precision: ', precision_score(y_test, predicted, average='weighted', zero_division=1))\n",
        "print('Recall: ', recall_score(y_test, predicted, average='weighted', zero_division=1))\n",
        "print('F1:', f1_score(y_test, predicted, average='weighted'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6278229448961157\n",
            "Precision:  0.6485532653841489\n",
            "Recall:  0.6278229448961157\n",
            "F1: 0.6150819361589105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCvOuPxQfTzK",
        "outputId": "7d230a01-c542-4c8f-e2d0-480b0ba8daf9"
      },
      "source": [
        "# precision, recall, fscore, support separated by label\n",
        "precision, recall, fscore, support = score(y_test, predicted)\n",
        "\n",
        "df_acc = pd.DataFrame()\n",
        "df_acc['precision']=pd.Series(precision)\n",
        "df_acc['recall']=pd.Series(recall)\n",
        "df_acc['fscore']=pd.Series(fscore)\n",
        "df_acc['support']=pd.Series(support)\n",
        "\n",
        "print(df_acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   precision    recall    fscore  support\n",
            "0   0.704545  0.446043  0.546256      556\n",
            "1   0.592053  0.811252  0.684533      551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z637Z0xKfiev",
        "outputId": "65d6f556-d4a1-4b07-f636-d258bb8bc70b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Matthews correlation coefficient\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_corrcoef(y_test, predicted)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2762488425224322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}