# Data Science Exam
*by Felicia Heilgendorff and Martine Greve*

In this project we built BERT, Na√Øve Bayes and LSTM models that classify stories either as remembered or imagined. We also built binary classification models that classify texts either as remembered or imagined based on external variables (not the story texts). Additionally, we did topic modeling on our texts.

Data is saved in [hippoCorpusV2.csv](hippoCorpusV2.csv) and was taken from:

Sap, M., Horvitz, E., Choi, Y., Smith, N.A., & Pennebaker, J. (2020). Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 1970-1978. https://doi.org/10.18653/v1/2020.acl-main.178

## Scripts

Topic modeling: [hippocorpus_topicmodeling.ipynb](hippocorpus_topicmodeling.ipynb) (including original category word clouds)

BERT: [Copy_of_Hippocorpus_BERT_Working_2.ipynb](Copy_of_Hippocorpus_BERT_Working_2.ipynb)

LSTM: [RNN_Working.ipynb](RNN_Working.ipynb)

Naive Bayes and SVM: [hippocorpus_NB_+_SVM.ipynb](hippocorpus_NB_+_SVM.ipynb)

XG Boost Model: [XGBoost.ipynb](XGBoost.ipynb)

Binary classification: [hippocorpus_binaryclass.ipynb](hippocorpus_binaryclass.ipynb) (including visualisations of data)
