{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feliciahf/data_science_exam/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZqO6BkcPctz"
      },
      "source": [
        "# XG Boost Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmprhr6qPZjS"
      },
      "source": [
        "From this article: https://suatatan.com/posts/sklearn_xgboost_tc/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rIdO5DhDSkU"
      },
      "source": [
        "# import relevant packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# accurcy\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import matthews_corrcoef"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPqvgg38DdIJ"
      },
      "source": [
        "##The data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN-D2YmFDXz9"
      },
      "source": [
        "# import csv file as dataframe (from GitHub repo)\n",
        "url = 'https://raw.githubusercontent.com/feliciahf/data_science_exam/main/hippoCorpusV2.csv'\n",
        "df = pd.read_csv(url, encoding='latin1', delimiter=\",\")\n",
        "\n",
        "# drop retold column (only using imagined and recalled)\n",
        "df = df[df.memType != 'retold']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QLB0qNzJqWm",
        "outputId": "132f1d5e-2144-4874-9c20-cd1322cf70d2"
      },
      "source": [
        "# make labels column using numerical values\n",
        "df.memType = pd.Categorical(df.memType)\n",
        "df['label'] = df.memType.cat.codes\n",
        "\n",
        "# story type corresponding to label\n",
        "print(f\"Label 0: {df.loc[df['label'] == 0,'memType'].unique()}\")\n",
        "print(f\"Label 1: {df.loc[df['label'] == 1,'memType'].unique()}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0: ['imagined']\n",
            "Categories (1, object): ['imagined']\n",
            "Label 1: ['recalled']\n",
            "Categories (1, object): ['recalled']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r-sL7oYEBgH"
      },
      "source": [
        "# preprocessing\n",
        "cv = CountVectorizer(max_features=5000, encoding=\"utf-8\",  \n",
        "      ngram_range = (1,3),  \n",
        "      token_pattern = \"[A-Za-z_][A-Za-z\\d_]*\")\n",
        "\n",
        "# split into story features (X) and categories (y)\n",
        "X = cv.fit_transform(df.story).toarray()\n",
        "y = df['label']\n",
        "\n",
        "# split into train and test data (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "      test_size=0.20,\n",
        "      random_state=0)\n",
        "count_df = pd.DataFrame(X_train, columns=cv.get_feature_names())\n",
        "count_df['label'] = y_train"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nc-PHalH_YI",
        "outputId": "94044e71-d648-4db3-e8ef-5b885ea92d6e"
      },
      "source": [
        "# fit model to training data\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# how well model does on training data\n",
        "yhat = model.predict(X_train)\n",
        "train_pred = [round(value) for value in yhat]\n",
        "acc_train = accuracy_score(y_train, train_pred)\n",
        "print(\"Accuracy on train data: %.2f%%\" % (acc_train * 100.0))\n",
        "\n",
        "# make predictions on test data\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "# evaluate predictions on test data\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy on test data: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train data: 81.01%\n",
            "Accuracy on test data: 69.65%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUJ8o_ln7xwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531f6c92-56c1-4a8e-e614-fa37ed4f7126"
      },
      "source": [
        "# compute overall accuracy, precision, recall, f1 scores (test data)\n",
        "print('Accuracy: ', accuracy_score(y_test, predictions))\n",
        "print('Precision: ', precision_score(y_test, predictions, average='weighted', zero_division=1))\n",
        "print('Recall: ', recall_score(y_test, predictions, average='weighted', zero_division=1))\n",
        "print('F1:', f1_score(y_test, predictions, average='weighted'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6964769647696477\n",
            "Precision:  0.6975740718848265\n",
            "Recall:  0.6964769647696477\n",
            "F1: 0.6959199816523208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkz8n6XoIrYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423d8d77-28f2-429f-8015-2061575c4f29"
      },
      "source": [
        "# print accuracy scores for each category\n",
        "print(classification_report(y_test, predictions, digits=3))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.684     0.738     0.710       557\n",
            "           1      0.711     0.655     0.682       550\n",
            "\n",
            "    accuracy                          0.696      1107\n",
            "   macro avg      0.698     0.696     0.696      1107\n",
            "weighted avg      0.698     0.696     0.696      1107\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI0WiGAzPNUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a24f95a-76ad-45e1-a251-13c2a4077268"
      },
      "source": [
        "# Matthews correlation coefficient\n",
        "matthews_corrcoef(y_test, predictions)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39387216194769925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fsfOIc_Ltmg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}