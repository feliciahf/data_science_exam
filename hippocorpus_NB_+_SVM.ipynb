{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hippocorpus_NB + SVM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feliciahf/data_science_exam/blob/main/hippocorpus_NB_%2B_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS0Vz4ExdBMZ"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTSjJzvmc9Xh",
        "outputId": "bd7176b4-4295-4b9d-8b86-275d884352a3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Naive Bayes model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Accuracies\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-b1BAaGdFhT"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDQVM-btdG3n"
      },
      "source": [
        "# import csv file as dataframe (from GitHub repo)\n",
        "url = 'https://raw.githubusercontent.com/feliciahf/data_science_exam/main/hippoCorpusV2.csv'\n",
        "df = pd.read_csv(url, encoding='latin1')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPxMdz5t5-0O"
      },
      "source": [
        "# drop retold label\n",
        "df = df[df.memType != 'retold']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ-xhwF_dKxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4a5b56-d991-4de1-b915-b802c877169f"
      },
      "source": [
        "# make labels column using numerical values\n",
        "df.memType = pd.Categorical(df.memType)\n",
        "df['label'] = df.memType.cat.codes\n",
        "\n",
        "# story type corresponding to label\n",
        "print(f\"Label 0: {df.loc[df['label'] == 0,'memType'].unique()}\")\n",
        "print(f\"Label 1: {df.loc[df['label'] == 1,'memType'].unique()}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0: ['imagined']\n",
            "Categories (1, object): ['imagined']\n",
            "Label 1: ['recalled']\n",
            "Categories (1, object): ['recalled']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT6l65DlddfO"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjTGF8paetXx"
      },
      "source": [
        "# case collapsing\n",
        "df['story'] = df.story.map(lambda x: x.lower())\n",
        "# remove punctuation\n",
        "df['story'] = df.story.str.replace('[^\\w\\s]', '')\n",
        "# tokenization\n",
        "df['story'] = df['story'].apply(nltk.word_tokenize)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eKr5f07eheW",
        "outputId": "19553fad-dddd-459e-eae7-d67186d4f5ba"
      },
      "source": [
        "# check whether preprocessing worked\n",
        "df['story']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [concerts, are, my, most, favorite, thing, and...\n",
              "1       [the, day, started, perfectly, with, a, great,...\n",
              "2       [it, seems, just, like, yesterday, but, today,...\n",
              "3       [five, months, ago, my, niece, and, nephew, we...\n",
              "4       [about, a, month, ago, i, went, to, burning, m...\n",
              "                              ...                        \n",
              "6849    [my, dog, was, diagnosed, with, lymphoma, a, y...\n",
              "6850    [over, my, vacation, from, my, job, i, went, t...\n",
              "6851    [this, event, was, a, birthday, party, for, my...\n",
              "6852    [this, event, occurred, about, two, weeks, ago...\n",
              "6853    [over, the, past, year, i, have, been, involve...\n",
              "Name: story, Length: 5535, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DolDvebrdrIy"
      },
      "source": [
        "# transform data into occurrences\n",
        "# This converts the list of words into space-separated strings\n",
        "df['story'] = df['story'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "counts = count_vect.fit_transform(df['story'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-SfavCqduKf"
      },
      "source": [
        "# tf-idf\n",
        "transformer = TfidfTransformer().fit(counts)\n",
        "counts = transformer.transform(counts)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs8TNY3mduf0"
      },
      "source": [
        "# Training NB model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEv68KmFgIXH"
      },
      "source": [
        "# split data into train (80%) and test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.2, random_state=69)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwCqa8Fvdwyv"
      },
      "source": [
        "# Fit model\n",
        "model = MultinomialNB().fit(X_train, y_train)\n",
        "# Test model\n",
        "predicted = model.predict(X_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSARKmwTfIb5"
      },
      "source": [
        "# Evaluating NB model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2gxHX8sfKiG",
        "outputId": "d6482342-5158-41b6-f001-131a5a571456"
      },
      "source": [
        "# compute overall accuracy, precision, recall, f1 scores\n",
        "print('Accuracy: ', accuracy_score(y_test, predicted))\n",
        "print('Precision: ', precision_score(y_test, predicted, average='weighted', zero_division=1))\n",
        "print('Recall: ', recall_score(y_test, predicted, average='weighted', zero_division=1))\n",
        "print('F1:', f1_score(y_test, predicted, average='weighted'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6278229448961157\n",
            "Precision:  0.6485532653841489\n",
            "Recall:  0.6278229448961157\n",
            "F1: 0.6150819361589105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCvOuPxQfTzK",
        "outputId": "bb10d85a-5980-4ea8-e2eb-a64495df0e40"
      },
      "source": [
        "# precision, recall, fscore, support (number of stories)\n",
        "precision, recall, fscore, support = score(y_test, predicted)\n",
        "\n",
        "# create dataframe with accuracies by category\n",
        "df_acc = pd.DataFrame()\n",
        "df_acc['precision']=pd.Series(precision)\n",
        "df_acc['recall']=pd.Series(recall)\n",
        "df_acc['fscore']=pd.Series(fscore)\n",
        "df_acc['support']=pd.Series(support)\n",
        "print(df_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   precision    recall    fscore  support\n",
            "0   0.704545  0.446043  0.546256      556\n",
            "1   0.592053  0.811252  0.684533      551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z637Z0xKfiev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f8d6ba-7067-4094-d2f5-fdf5bdd66e78"
      },
      "source": [
        "# Matthews correlation coefficient\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_corrcoef(y_test, predicted)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2762488425224322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX-KijH2VBqR"
      },
      "source": [
        "##The SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3858gMEUyGF"
      },
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpxPDRkpVLzq"
      },
      "source": [
        "##Evaluate SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNN-fIerm79D",
        "outputId": "6d82096f-7201-41e7-e53b-0cfaf8b28bea"
      },
      "source": [
        "# compute overall accuracy, precision, recall, f1 scores\n",
        "print('Accuracy: ', accuracy_score(y_test,y_pred))\n",
        "print('Precision: ', precision_score(y_test, y_pred, average='weighted', zero_division=1))\n",
        "print('Recall: ', recall_score(y_test, y_pred, average='weighted', zero_division=1))\n",
        "print('F1:', f1_score(y_test, y_pred, average='weighted'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7091237579042458\n",
            "Precision:  0.7091441742201728\n",
            "Recall:  0.7091237579042458\n",
            "F1: 0.7091247073569915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XhEiYELVVNB",
        "outputId": "1e59181b-67dd-4aa6-8ce4-0e2bce0f4f2f"
      },
      "source": [
        "# precision, recall, fscore, support (number of stories)\n",
        "precision, recall, fscore, support = score(y_test, y_pred)\n",
        "\n",
        "# create dataframe with accuracies by category\n",
        "df_acc = pd.DataFrame()\n",
        "df_acc['precision']=pd.Series(precision)\n",
        "df_acc['recall']=pd.Series(recall)\n",
        "df_acc['fscore']=pd.Series(fscore)\n",
        "df_acc['support']=pd.Series(support)\n",
        "print(df_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   precision    recall    fscore  support\n",
            "0   0.711957  0.706835  0.709386      556\n",
            "1   0.706306  0.711434  0.708861      551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNMkPR0ZVDOU",
        "outputId": "e3d04038-d0db-4f0c-a66e-29f62d68fda6"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7091237579042458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LczJzSgVOu5",
        "outputId": "93c17e6e-6a96-4f4d-d316-118b10a297d1"
      },
      "source": [
        "# Matthews correlation coefficient\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_corrcoef(y_test, y_pred)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4182655586037596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFxaS99sVhbA"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}